// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/debug/debug_service.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow/core/debug/debug_service.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {

namespace {

const ::google::protobuf::Descriptor* EventReply_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  EventReply_reflection_ = NULL;

}  // namespace


void protobuf_AssignDesc_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto() GOOGLE_ATTRIBUTE_COLD;
void protobuf_AssignDesc_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto() {
  protobuf_AddDesc_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto();
  const ::google::protobuf::FileDescriptor* file =
    ::google::protobuf::DescriptorPool::generated_pool()->FindFileByName(
      "tensorflow/core/debug/debug_service.proto");
  GOOGLE_CHECK(file != NULL);
  EventReply_descriptor_ = file->message_type(0);
  static const int EventReply_offsets_[1] = {
  };
  EventReply_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      EventReply_descriptor_,
      EventReply::internal_default_instance(),
      EventReply_offsets_,
      -1,
      -1,
      -1,
      sizeof(EventReply),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(EventReply, _internal_metadata_));
}

namespace {

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AssignDescriptors_once_);
void protobuf_AssignDescriptorsOnce() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AssignDescriptors_once_,
                 &protobuf_AssignDesc_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      EventReply_descriptor_, EventReply::internal_default_instance());
}

}  // namespace

void protobuf_ShutdownFile_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto() {
  EventReply_default_instance_.Shutdown();
  delete EventReply_reflection_;
}

void protobuf_InitDefaults_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto_impl() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2fevent_2eproto();
  EventReply_default_instance_.DefaultConstruct();
  EventReply_default_instance_.get_mutable()->InitAsDefaultInstance();
}

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_InitDefaults_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto_once_);
void protobuf_InitDefaults_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto() {
  ::google::protobuf::GoogleOnceInit(&protobuf_InitDefaults_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto_once_,
                 &protobuf_InitDefaults_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto_impl);
}
void protobuf_AddDesc_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto_impl() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  protobuf_InitDefaults_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto();
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
    "\n)tensorflow/core/debug/debug_service.pr"
    "oto\022\ntensorflow\032 tensorflow/core/util/ev"
    "ent.proto\"\014\n\nEventReply2L\n\rEventListener"
    "\022;\n\nSendEvents\022\021.tensorflow.Event\032\026.tens"
    "orflow.EventReply(\0010\001b\006proto3", 189);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow/core/debug/debug_service.proto", &protobuf_RegisterTypes);
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2futil_2fevent_2eproto();
  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto);
}

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AddDesc_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto_once_);
void protobuf_AddDesc_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AddDesc_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto_once_,
                 &protobuf_AddDesc_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto_impl);
}
// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto {
  StaticDescriptorInitializer_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto() {
    protobuf_AddDesc_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto();
  }
} static_descriptor_initializer_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto_;

namespace {

static void MergeFromFail(int line) GOOGLE_ATTRIBUTE_COLD GOOGLE_ATTRIBUTE_NORETURN;
static void MergeFromFail(int line) {
  ::google::protobuf::internal::MergeFromFail(__FILE__, line);
}

}  // namespace


// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

EventReply::EventReply()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (this != internal_default_instance()) protobuf_InitDefaults_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto();
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.EventReply)
}

void EventReply::InitAsDefaultInstance() {
}

EventReply::EventReply(const EventReply& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  UnsafeMergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.EventReply)
}

void EventReply::SharedCtor() {
  _cached_size_ = 0;
}

EventReply::~EventReply() {
  // @@protoc_insertion_point(destructor:tensorflow.EventReply)
  SharedDtor();
}

void EventReply::SharedDtor() {
}

void EventReply::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* EventReply::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return EventReply_descriptor_;
}

const EventReply& EventReply::default_instance() {
  protobuf_InitDefaults_tensorflow_2fcore_2fdebug_2fdebug_5fservice_2eproto();
  return *internal_default_instance();
}

::google::protobuf::internal::ExplicitlyConstructed<EventReply> EventReply_default_instance_;

EventReply* EventReply::New(::google::protobuf::Arena* arena) const {
  EventReply* n = new EventReply;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void EventReply::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.EventReply)
}

bool EventReply::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.EventReply)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
  handle_unusual:
    if (tag == 0 ||
        ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
        ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
      goto success;
    }
    DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.EventReply)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.EventReply)
  return false;
#undef DO_
}

void EventReply::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.EventReply)
  // @@protoc_insertion_point(serialize_end:tensorflow.EventReply)
}

::google::protobuf::uint8* EventReply::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.EventReply)
  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.EventReply)
  return target;
}

size_t EventReply::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.EventReply)
  size_t total_size = 0;

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void EventReply::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.EventReply)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const EventReply* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const EventReply>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.EventReply)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.EventReply)
    UnsafeMergeFrom(*source);
  }
}

void EventReply::MergeFrom(const EventReply& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.EventReply)
  if (GOOGLE_PREDICT_TRUE(&from != this)) {
    UnsafeMergeFrom(from);
  } else {
    MergeFromFail(__LINE__);
  }
}

void EventReply::UnsafeMergeFrom(const EventReply& from) {
  GOOGLE_DCHECK(&from != this);
}

void EventReply::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.EventReply)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void EventReply::CopyFrom(const EventReply& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.EventReply)
  if (&from == this) return;
  Clear();
  UnsafeMergeFrom(from);
}

bool EventReply::IsInitialized() const {

  return true;
}

void EventReply::Swap(EventReply* other) {
  if (other == this) return;
  InternalSwap(other);
}
void EventReply::InternalSwap(EventReply* other) {
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata EventReply::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = EventReply_descriptor_;
  metadata.reflection = EventReply_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// EventReply

inline const EventReply* EventReply::internal_default_instance() {
  return &EventReply_default_instance_.get();
}
#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
